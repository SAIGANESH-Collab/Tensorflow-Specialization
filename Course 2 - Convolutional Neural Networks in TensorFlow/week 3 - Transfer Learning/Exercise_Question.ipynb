{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7ab4d86-5ca2-4ce0-d557-d58e98aa6f75"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape=(150, 150, 3),\n",
        "                                include_top=False,\n",
        "                                weights=None\n",
        "                                )\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-29 21:04:23--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.187.128, 2404:6800:4008:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.187.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep  47%[========>           ]  40.01M   114MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M   156MB/s    in 0.5s    \n",
            "\n",
            "2019-12-29 21:04:24 (156 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9b397e0b-5c3b-4a4a-ee9a-662eda65c9b7"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0a9a84d-2de1-4aa3-8562-2089198ff03f"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "e056a688-d0bd-40b2-cf5a-6e5f6cc170a5"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-29 21:08:59--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.97.128, 2404:6800:4008:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.97.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  86.9MB/s    in 1.6s    \n",
            "\n",
            "2019-12-29 21:09:01 (86.9 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-12-29 21:09:03--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.187.128, 2404:6800:4008:c04::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.187.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-12-29 21:09:03 (146 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "2455bdfa-e2d5-4f51-9fbb-1c52fe73cd2b"
      },
      "source": [
        "train_horses_dir = \"/tmp/training/horses\" # Your Code Here\n",
        "train_humans_dir = \"/tmp/training/humans\" # Your Code Here\n",
        "validation_horses_dir = \"/tmp/validation/horses\" # Your Code Here\n",
        "validation_humans_dir = \"/tmp/validation/humans\" # Your Code Here\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir) # Your Code Here\n",
        "train_humans_fnames = os.listdir(train_humans_dir) # Your Code Here\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir) # Your Code Here\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir) # Your Code Here\n",
        "\n",
        "print(len(train_horses_fnames)) # Your Code Here\n",
        "print(len(train_humans_fnames)) # Your Code Here\n",
        "print(len(validation_horses_fnames)) # Your Code Here\n",
        "print(len(validation_humans_fnames)) # Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5fe52fd6-2cb0-4c64-9636-41f71b012d93"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    height_shift_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        " )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size = 20,\n",
        "    class_mode = 'binary', \n",
        "    target_size = (150, 150)\n",
        ")     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    batch_size = 20,\n",
        "    class_mode = 'binary',\n",
        "    target_size = (150, 150)\n",
        ")\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ef113877-a6d1-4913-ee23-4693a7b989e9"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    steps_per_epoch=100,\n",
        "    validation_steps=50,\n",
        "    epochs=100,\n",
        "    callbacks=[callbacks]\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9278Epoch 1/100\n",
            "100/100 [==============================] - 31s 306ms/step - loss: 0.1851 - acc: 0.9276 - val_loss: 0.0042 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9826Epoch 1/100\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0623 - acc: 0.9828 - val_loss: 0.1157 - val_acc: 0.9767\n",
            "Epoch 3/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9846Epoch 1/100\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0401 - acc: 0.9848 - val_loss: 0.0238 - val_acc: 0.9919\n",
            "Epoch 4/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9862Epoch 1/100\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0375 - acc: 0.9863 - val_loss: 0.0343 - val_acc: 0.9889\n",
            "Epoch 5/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9852Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0456 - acc: 0.9853 - val_loss: 0.0468 - val_acc: 0.9879\n",
            "Epoch 6/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9841Epoch 1/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0412 - acc: 0.9843 - val_loss: 0.0588 - val_acc: 0.9838\n",
            "Epoch 7/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9898Epoch 1/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0301 - acc: 0.9899 - val_loss: 0.0308 - val_acc: 0.9919\n",
            "Epoch 8/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9851Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0518 - acc: 0.9852 - val_loss: 0.0341 - val_acc: 0.9929\n",
            "Epoch 9/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9939Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0154 - acc: 0.9939 - val_loss: 0.1153 - val_acc: 0.9767\n",
            "Epoch 10/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9944Epoch 1/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0224 - acc: 0.9940 - val_loss: 0.4072 - val_acc: 0.9565\n",
            "Epoch 11/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9928Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0368 - acc: 0.9929 - val_loss: 0.0445 - val_acc: 0.9919\n",
            "Epoch 12/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9959Epoch 1/100\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0131 - acc: 0.9954 - val_loss: 0.4037 - val_acc: 0.9605\n",
            "Epoch 13/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9933Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0185 - acc: 0.9934 - val_loss: 0.2920 - val_acc: 0.9615\n",
            "Epoch 14/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9933Epoch 1/100\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.0230 - acc: 0.9929 - val_loss: 0.0542 - val_acc: 0.9879\n",
            "Epoch 15/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9923Epoch 1/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0205 - acc: 0.9924 - val_loss: 0.0798 - val_acc: 0.9879\n",
            "Epoch 16/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9908Epoch 1/100\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0380 - acc: 0.9909 - val_loss: 0.1886 - val_acc: 0.9686\n",
            "Epoch 17/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9974Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0120 - acc: 0.9975 - val_loss: 0.1782 - val_acc: 0.9757\n",
            "Epoch 18/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9974Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0195 - acc: 0.9975 - val_loss: 0.3060 - val_acc: 0.9696\n",
            "Epoch 19/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9939Epoch 1/100\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0218 - acc: 0.9929 - val_loss: 0.0818 - val_acc: 0.9929\n",
            "Epoch 20/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9985Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0066 - acc: 0.9985 - val_loss: 0.1781 - val_acc: 0.9767\n",
            "Epoch 21/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9948Epoch 1/100\n",
            "100/100 [==============================] - 22s 215ms/step - loss: 0.0139 - acc: 0.9949 - val_loss: 0.3430 - val_acc: 0.9767\n",
            "Epoch 22/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9969Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0082 - acc: 0.9970 - val_loss: 0.3376 - val_acc: 0.9757\n",
            "Epoch 23/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9959Epoch 1/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0151 - acc: 0.9959 - val_loss: 0.5272 - val_acc: 0.9636\n",
            "Epoch 24/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9974Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0048 - acc: 0.9975 - val_loss: 0.5336 - val_acc: 0.9646\n",
            "Epoch 25/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9939Epoch 1/100\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.0297 - acc: 0.9939 - val_loss: 0.4516 - val_acc: 0.9676\n",
            "Epoch 26/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9949Epoch 1/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0240 - acc: 0.9944 - val_loss: 0.6130 - val_acc: 0.9605\n",
            "Epoch 27/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9933Epoch 1/100\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.0186 - acc: 0.9934 - val_loss: 0.2636 - val_acc: 0.9757\n",
            "Epoch 28/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9969Epoch 1/100\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0084 - acc: 0.9970 - val_loss: 0.4980 - val_acc: 0.9686\n",
            "Epoch 29/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9974Epoch 1/100\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0055 - acc: 0.9975 - val_loss: 0.8369 - val_acc: 0.9494\n",
            "Epoch 30/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9985Epoch 1/100\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0106 - acc: 0.9985 - val_loss: 0.3737 - val_acc: 0.9737\n",
            "Epoch 31/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9975Epoch 1/100\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0053 - acc: 0.9975 - val_loss: 0.7202 - val_acc: 0.9484\n",
            "Epoch 32/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9974Epoch 1/100\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.0106 - acc: 0.9975 - val_loss: 0.5375 - val_acc: 0.9636\n",
            "Epoch 33/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9923Epoch 1/100\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0271 - acc: 0.9919 - val_loss: 0.7547 - val_acc: 0.9575\n",
            "Epoch 34/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9964Epoch 1/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0079 - acc: 0.9965 - val_loss: 0.7741 - val_acc: 0.9494\n",
            "Epoch 35/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9980Epoch 1/100\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0096 - acc: 0.9980 - val_loss: 1.5855 - val_acc: 0.9372\n",
            "Epoch 36/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9969Epoch 1/100\n",
            "100/100 [==============================] - 22s 215ms/step - loss: 0.0181 - acc: 0.9969 - val_loss: 1.2805 - val_acc: 0.9413\n",
            "Epoch 37/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9980Epoch 1/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0117 - acc: 0.9980 - val_loss: 0.6826 - val_acc: 0.9575\n",
            "Epoch 38/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9975Epoch 1/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0072 - acc: 0.9975 - val_loss: 1.0331 - val_acc: 0.9453\n",
            "Epoch 39/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9990Epoch 1/100\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0041 - acc: 0.9990 - val_loss: 0.8263 - val_acc: 0.9494\n",
            "Epoch 40/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9964Epoch 1/100\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.0132 - acc: 0.9965 - val_loss: 0.6799 - val_acc: 0.9615\n",
            "Epoch 41/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9959Epoch 1/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0220 - acc: 0.9959 - val_loss: 0.5809 - val_acc: 0.9656\n",
            "Epoch 42/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9954Epoch 1/100\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0153 - acc: 0.9954 - val_loss: 0.6707 - val_acc: 0.9575\n",
            "Epoch 43/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9969Epoch 1/100\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.0106 - acc: 0.9970 - val_loss: 0.7903 - val_acc: 0.9474\n",
            "Epoch 44/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9944Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0178 - acc: 0.9944 - val_loss: 0.9434 - val_acc: 0.9504\n",
            "Epoch 45/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9985Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.1834 - val_acc: 0.9879\n",
            "Epoch 46/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9980Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.6230 - val_acc: 0.9676\n",
            "Epoch 47/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9954Epoch 1/100\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.0227 - acc: 0.9954 - val_loss: 0.7105 - val_acc: 0.9524\n",
            "Epoch 48/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9948Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0191 - acc: 0.9949 - val_loss: 0.4493 - val_acc: 0.9727\n",
            "Epoch 49/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9990Epoch 1/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0066 - acc: 0.9990 - val_loss: 0.6913 - val_acc: 0.9575\n",
            "Epoch 50/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9964Epoch 1/100\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0116 - acc: 0.9965 - val_loss: 0.9518 - val_acc: 0.9464\n",
            "Epoch 51/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9959Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0101 - acc: 0.9960 - val_loss: 0.6703 - val_acc: 0.9575\n",
            "Epoch 52/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9990Epoch 1/100\n",
            "100/100 [==============================] - 22s 215ms/step - loss: 0.0014 - acc: 0.9990 - val_loss: 0.9926 - val_acc: 0.9524\n",
            "Epoch 53/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9954Epoch 1/100\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.0199 - acc: 0.9954 - val_loss: 0.5850 - val_acc: 0.9656\n",
            "Epoch 54/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9969Epoch 1/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0106 - acc: 0.9970 - val_loss: 0.5394 - val_acc: 0.9676\n",
            "Epoch 55/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9949Epoch 1/100\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0155 - acc: 0.9950 - val_loss: 0.7400 - val_acc: 0.9565\n",
            "Epoch 56/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9979Epoch 1/100\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0077 - acc: 0.9980 - val_loss: 0.4688 - val_acc: 0.9727\n",
            "Epoch 57/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9969Epoch 1/100\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0106 - acc: 0.9970 - val_loss: 0.5878 - val_acc: 0.9696\n",
            "Epoch 58/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9974Epoch 1/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0053 - acc: 0.9975 - val_loss: 0.5882 - val_acc: 0.9615\n",
            "Epoch 59/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9980Epoch 1/100\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.0140 - acc: 0.9975 - val_loss: 0.4287 - val_acc: 0.9777\n",
            "Epoch 60/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9974Epoch 1/100\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0251 - acc: 0.9975 - val_loss: 0.5815 - val_acc: 0.9615\n",
            "Epoch 61/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9980Epoch 1/100\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0057 - acc: 0.9980 - val_loss: 0.5285 - val_acc: 0.9656\n",
            "Epoch 62/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9943Epoch 1/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0212 - acc: 0.9939 - val_loss: 1.0480 - val_acc: 0.9474\n",
            "Epoch 63/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9980Epoch 1/100\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0098 - acc: 0.9980 - val_loss: 0.6072 - val_acc: 0.9615\n",
            "Epoch 64/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9964Epoch 1/100\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0177 - acc: 0.9965 - val_loss: 0.8478 - val_acc: 0.9545\n",
            "Epoch 65/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9990Epoch 1/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.8841 - val_acc: 0.9484\n",
            "Epoch 66/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9985Epoch 1/100\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 1.0742 - val_acc: 0.9443\n",
            "Epoch 67/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9964Epoch 1/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0195 - acc: 0.9965 - val_loss: 0.9421 - val_acc: 0.9453\n",
            "Epoch 68/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9980Epoch 1/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0049 - acc: 0.9980 - val_loss: 0.9078 - val_acc: 0.9504\n",
            "Epoch 69/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9954Epoch 1/100\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.0192 - acc: 0.9954 - val_loss: 1.0291 - val_acc: 0.9494\n",
            "Epoch 70/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9974Epoch 1/100\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.0113 - acc: 0.9975 - val_loss: 0.8340 - val_acc: 0.9585\n",
            "Epoch 71/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9980Epoch 1/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0125 - acc: 0.9980 - val_loss: 0.7374 - val_acc: 0.9605\n",
            "Epoch 72/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9985Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0079 - acc: 0.9985 - val_loss: 1.1622 - val_acc: 0.9474\n",
            "Epoch 73/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9975Epoch 1/100\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0096 - acc: 0.9975 - val_loss: 1.0818 - val_acc: 0.9453\n",
            "Epoch 74/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9979Epoch 1/100\n",
            "100/100 [==============================] - 22s 215ms/step - loss: 0.0109 - acc: 0.9980 - val_loss: 1.0428 - val_acc: 0.9484\n",
            "Epoch 75/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9985Epoch 1/100\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0104 - acc: 0.9985 - val_loss: 0.7371 - val_acc: 0.9575\n",
            "Epoch 76/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9990Epoch 1/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0038 - acc: 0.9990 - val_loss: 0.8260 - val_acc: 0.9555\n",
            "Epoch 77/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9974Epoch 1/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0180 - acc: 0.9975 - val_loss: 0.9556 - val_acc: 0.9545\n",
            "Epoch 78/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9939Epoch 1/100\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0471 - acc: 0.9939 - val_loss: 0.7068 - val_acc: 0.9605\n",
            "Epoch 79/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9959Epoch 1/100\n",
            "100/100 [==============================] - 21s 211ms/step - loss: 0.0143 - acc: 0.9959 - val_loss: 1.1437 - val_acc: 0.9545\n",
            "Epoch 80/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9980Epoch 1/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0043 - acc: 0.9980 - val_loss: 0.9195 - val_acc: 0.9595\n",
            "Epoch 81/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9985Epoch 1/100\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0063 - acc: 0.9985 - val_loss: 0.5256 - val_acc: 0.9727\n",
            "Epoch 82/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 2.8729e-04 - acc: 1.0000Epoch 1/100\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.2582 - acc: 0.9423\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 2.8446e-04 - acc: 1.0000 - val_loss: 1.2582 - val_acc: 0.9423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "c4489f68-5a1b-4679-9590-d16c8496a081"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOydeXxU5fX/PycLEPYkJIAhEEBEQmQX\nEVQQV9wVFVy+roi2xa1q1brzc61YW63aqkWrtgilahFRZJEqgrKDAgYQEAgkYU1YQtbz++PMw71z\nc+/MnX0yed6v17xm5q7P3T7Puec5z3mImaHRaDSaxCUp1gXQaDQaTWTRQq/RaDQJjhZ6jUajSXC0\n0Gs0Gk2Co4Veo9FoEhwt9BqNRpPgaKFvhBBRMhEdIqLO4Vw2lhDR8UQU9lhhIjqbiLaa/hcS0elu\nlg1iX28T0e+DXV+jcSIl1gXQ+IeIDpn+NgdQCaDW8/92Zv5nINtj5loALcO9bGOAmXuGYztENA7A\n9cw8wrTtceHYtkZjRQt9A4CZjwmtx2Icx8xznZYnohRmrolG2TQaf+j7MfZo100CQERPE9FUIppC\nRAcBXE9EpxLRd0R0gIh2EdErRJTqWT6FiJiI8jz/P/DM/5yIDhLRYiLqGuiynvmjiGgDEZUR0atE\n9C0R3eRQbjdlvJ2INhHRfiJ6xbRuMhG9TER7iWgzgPN9nJ9HiOhDy7TXiOiPnt/jiGi953h+9ljb\nTtvaQUQjPL+bE9H7nrKtBTDQsuyjRLTZs921RHSJZ/pJAP4C4HSPW2yP6dw+aVr/Ds+x7yWiT4io\no5tzE8h5VuUhorlEtI+Iionod6b9POY5J+VEtIyIjrNzkxHRQnWdPefza89+9gF4lIh6ENFXnn3s\n8Zy3Nqb1u3iOcbdn/p+JqJmnzL1My3UkoiNElOl0vBobmFl/GtAHwFYAZ1umPQ2gCsDFkMo7DcDJ\nAE6BvLV1A7ABwATP8ikAGECe5/8HAPYAGAQgFcBUAB8EsWw2gIMALvXM+y2AagA3ORyLmzL+F0Ab\nAHkA9qljBzABwFoAnQBkAvhabmfb/XQDcAhAC9O2SwEM8vy/2LMMARgJoAJAH8+8swFsNW1rB4AR\nnt+TACwAkA6gC4B1lmWvBtDRc02u9ZShvWfeOAALLOX8AMCTnt/nesrYD0AzAK8DmO/m3AR4ntsA\nKAFwN4CmAFoDGOyZ9zCA1QB6eI6hH4AMAMdbzzWAheo6e46tBsCvACRD7scTAJwFoInnPvkWwCTT\n8fzoOZ8tPMsP88x7E8Azpv3cB+DjWD+HDe0T8wLoT4AXzFno5/tZ734A//b8thPvv5qWvQTAj0Es\newuAb0zzCMAuOAi9yzIOMc3/CMD9nt9fQ1xYat4FVvGxbPs7ANd6fo8CUOhj2ZkAfuP57Uvot5mv\nBYBfm5e12e6PAC70/PYn9P8A8KxpXmtIu0wnf+cmwPP8fwCWOiz3syqvZbobod/spwxXqv0COB1A\nMYBkm+WGAdgCgDz/VwG4ItzPVaJ/tOsmcdhu/kNEJxLRZ55X8XIAEwG087F+sen3EfhugHVa9jhz\nOViezB1OG3FZRlf7AvCLj/ICwL8AXOP5fa3nvyrHRUT0vcetcABiTfs6V4qOvspARDcR0WqP++EA\ngBNdbheQ4zu2PWYuB7AfQI5pGVfXzM95zoUIuh2+5vnDej92IKJpRFTkKcO7ljJsZWn494KZv4W8\nHZxGRAUAOgP4LMgyNVq00CcO1tDCv0EsyOOZuTWAxyEWdiTZBbE4AQBERPAWJiuhlHEXRCAU/sI/\npwE4m4hyIK6lf3nKmAZgOoDnIG6VtgC+dFmOYqcyEFE3AG9A3BeZnu3+ZNquv1DQnRB3kNpeK4iL\nqMhFuaz4Os/bAXR3WM9p3mFPmZqbpnWwLGM9vhcg0WInecpwk6UMXYgo2aEc7wG4HvL2MY2ZKx2W\n0zighT5xaQWgDMBhT2PW7VHY50wAA4joYiJKgfh9syJUxmkA7iGiHE/D3IO+FmbmYoh74V2I22aj\nZ1ZTiN94N4BaIroI4kt2W4bfE1Fbkn4GE0zzWkLEbjekzrsNYtErSgB0MjeKWpgC4FYi6kNETSEV\n0TfM7PiG5ANf53kGgM5ENIGImhJRayIa7Jn3NoCniag7Cf2IKANSwRVDGv2TiWg8TJWSjzIcBlBG\nRLkQ95FiMYC9AJ4laeBOI6JhpvnvQ1w910JEXxMgWugTl/sA3AhpHP0bpNE0ojBzCYAxAP4IeXC7\nA1gJseTCXcY3AMwD8AOApRCr3B//gvjcj7ltmPkAgHsBfAxp0LwSUmG54QnIm8VWAJ/DJELMvAbA\nqwCWeJbpCeB707pzAGwEUEJEZheMWv8LiIvlY8/6nQFc57JcVhzPMzOXATgHwGhI5bMBwHDP7BcB\nfAI5z+WQhtFmHpfcbQB+D2mYP95ybHY8AWAwpMKZAeA/pjLUALgIQC+Idb8Nch3U/K2Q61zJzIsC\nPHYNjAYOjSbseF7FdwK4kpm/iXV5NA0XInoP0sD7ZKzL0hDRHaY0YYWIzodEuFRAwvOqIVatRhMU\nnvaOSwGcFOuyNFS060YTbk4DsBnimz4PwOW68UwTLET0HCSW/1lm3hbr8jRUtOtGo9FoEhxt0Ws0\nGk2CE3c++nbt2nFeXl6si6HRaDQNiuXLl+9hZttw5rgT+ry8PCxbtizWxdBoNJoGBRE59g7XrhuN\nRqNJcLTQazQaTYKjhV6j0WgSHC30Go1Gk+BooddoNJoEx6/QE9FkIioloh8d5pNnyLBNRLSGiAaY\n5t1IRBs9nxvDWXCNRqPRuMONRf8ufIzHCRmtp4fnMx6SVRCedKZPQIYwGwzgCSJKD6WwGo1Gowkc\nv0LPzF9D0rc6cSmA91j4DkBbkkGMzwMwh5n3MfN+SFpWXxVGSJSXA08+CSzR6bM0Gk1D5KOPgH/+\nMyKbDoePPgfew4bt8Exzml4PIhrvGWF+2e7du4MqRE0N8NRTwOLFQa2u0Wg0sWPBAuCaa4A33gBq\n642oGDJx0RjLzG8y8yBmHpSV5WtAImdat5bvsrIwFkyj0WgizerVwKWXAt27AzNmAMlOIyoGTziE\nvgje42Z28kxzmh4RUlKAFi200GuCYO1a4NZbgT17Yl0SbyZPBv74R3fLLl0KjB8vr7YNlY8+Am64\nAZg5E6iujnVp6lNSItfj8suBTZvCs80tW4DzzxdLdfZsICMjPNu1wsx+PwDyAPzoMO9CyDBqBGAI\ngCWe6RkAtkAGNE73/M7wt6+BAwdysBx3HPOttwa9emKzeTPzjz/GuhTe1NUxz5nDXFYWuzJs2SI3\nDsA8YULsymGlupo5K4s5KYl57Vr/yw8fLscwY0bEixYRDhxgbtdOjgFgzs5mvuce5q1bw7+vvXuZ\nv/mGuabG/7JHjzL/+9/MF17InJwsZWvShLlrV+Zdu0Irx8aNzD16MKenu7vGfgCwjJ003GkGG0I+\nBTJmZTXEz34rgDsA3OGZTwBeA/AzZFzHQaZ1bwGwyfO52d++OESh79WL+corg149sRk5krlDBxGQ\neGD3bnl4AOZu3Zi//z76ZSgpkQetbVvmiy5iTklh3rAhvPuoqxNBqasLbL05cwzRu/hi38suWWIs\ne+mlwZc1lvz+91L+RYuY//tf5tGjRVCPP5750CH7dQI5p4cOMU+ZIucyNVX2NXw487Zt9ttdvlwq\n/owMWfa445gffJB53Trm775jbt6cuV+/wI2UAweY33qL+fTTZbvNmzN/+21g23AgJKGP9icUoR8y\nhPnss4NePXGpqGBu2jR+LL4FC+TBadJEHvDOnUVkn3+eubY2uG1OmcKcm8v8/vv1523YIA9Wnz7M\nzz3H/MsvzOXlzAMHMqelMS9cKNZZixbMV10V2rFZGTvWEGEi5mbNmN980/96t93G3LIl8+OPy7pf\nf+287FVXMbduzfyrX4nVGail+dlnzL17y3ew7N7N/PLLzAUFzGeeab9MaalUrH/5i/f0HTvkOowd\n6z19/nw59jvvrL+td9+V+2bdOucy1dXJebv5ZjmXAHNODvN99zH/6U9yvdPTxWJnZt60ifmZZ+QY\nAHlmxoxh/vzz+tb/rFlyz44cKVa/GxYvln0CzD17Mj/7LPP27e7WdUGjEfrzzmM++eSgV294vPIK\n8+23G5+775bXUiv/+58hNpddFvh+5s83HoZQ2LhRHrKkJOYTTmBeuVKm79snr2KA1NY33CAP57hx\n7kRx9myx0tTDfOutzIcPy7wPP2Ru1Uoss6FDjfPQoYOI4syZxnaeeELmhevtYts2EfcLL5RtP/qo\n3KBt2jDv2eO8XlUVc2Ym87XXMh85IuJ0yin2FuzPP8v5/N3vmAsLpfzPP+++jHV1zH37Guflzjtl\nn+bt/+EPzHfdxXzHHXJdrr+e+aabmMePl+WvvFIqbSWkgL2b8PXXjQrvww+N6ePGyfX7+ef669x1\nl6wzb54x7bPPDDeK0/38j38wd+8uy7RsyXzLLcxffeUt2Bs3yvUA5H5U52DYMObXXpP70hf/+Ics\nf+21vpdjlvuxRw/mLl3k/gr0Dc8FjUbox4yR69UoOHBALl+rVszt24tPExBLxcrEifJw3XqrWCHF\nxfWXWb/e3q0zZ448hE2b+r/x7Th0iPmvfzVElkjE4uBB7+Xq6uSVtlcv5rw85k6dxEpNTTVE244l\nS8RK6ttXxPORR2QfBQVyvADzqaeKFc8sbRVPP808eDDzv/7lva3ycjmPw4cH9iDanU9mOe+A7FPx\nww8izL/9rfP2vvhC1vvkE/n/97/Lf7vK9je/kXNUVCT/Tz9dHgJr+XfvlgrEyuzZsu3XXxefOCDW\n/TPPMA8aZIhf27Zybjp1Ev90585SWWZkMHfsKEbGmjXyNkEkFZuVESOkbKefLhXDvHnim05KEkG3\nQwlk587iJlFukwEDxJUCiKVs5vvvZZuDBokYO7l+mOWcPPYY8xlnSIUWaJvAY49JGVat8r2cqrDm\nzw9s+wHQaIR+/HjRvEbB3Lly+WbPNqb16iWvklbOOkuEcN06WefFF73nT5vGx3yWSjCYxU/ZsqVY\nIUD9V243KNdFfj7zCy/Ia7pbZs6sb82ZKSyUBry8POadO43pX3xhNOw98IC9wDnx2muy3qefulv+\nqae8RVlRWyvlOuus+uvccosI3ZYt9tu85Rap5Coq5H9NjYhvjx7ex7J7t7g8brrJmPbuu1zP1fP9\n91IZXnxx/Qrg7LPFjabcD198IQIOiFC++KJRSbplxAi5F837MlcA+/bJ8bRqJW9wrVuLW8eJRYtE\nuC+5RN50unWTyvXgQXngzRVzRQXziSdKhXTgQGDlDoY9e+Ra2rmXFMoF5VSZhYlGI/QPPCAu0EbB\ns8/K5TO7an73O7HYzTd4ZaWIgbrJTj3V+yEsLRVRPP54sZSysqTy2LhRLLguXUT8+/eXxqdAKCmR\n8tx5Z3CvqgcOyAP+2GP151VUyAOflWXfgFpczLx0aeD7rKoSQc3NFSvXzhWmeOMNuQYpKWKpmkVY\nVcTWtwZm8cs2a8Z83XX151VWit/4//7Pe/qnn8r2Lr9cfMbV1UYlY3aTHDokwnnDDfL/p5/k+iq3\nltkVtny5THvhBe99HTwYmu9YuWh++MGY9pe/eJd1+3YRY0DeHvzx0EOyrPV6q+3OmiX/f/c7+f/F\nF8GXP1DGjpVrpipmM2Vl8gz16OH7zTQMNBqhf/ppOaLKyqA30XC4/HIRZzMLF8oJMPs/1bT//Ef+\nv/02e73uXn21WCQ//iiv0b17i+WVlSXW008/yXLqgVq+3H0ZJ02SdUIJHRs4UF6rrShrPxKNy998\nI+dBhdKNHi2RIOYba/p0w//+n//Ism+8Ycy/5hrnh5/ZEK4VK7ynz5pl/0ZRVyeuijZtZH67diLo\nF1xQf9u33y6V+7p1IjJZWfL2c9ZZYtlv2iTLjR0rVnW4Ld/i4voV9BlnyFudmfXr5ZjcCODRo7Ks\natdRVFZKhd+3r0SvJCVJQ3Y0URFSU6bUnzdunJRp0aKIF6PRCP2rr8oR+XoLjDm1teFpiMnJqd8I\nVFMjAmC2FJ95Rk7K7t3yv7xcLPfbbjME6umnjeUPHxbXQXq6d6Pkvn1ihf761+7KV1cnbw5DhgR3\nfIrf/lbaB6yCOX68WKluIx4CRYXY3X23CKUS1zvvZJ48WSqAIUPkfNXVMZ92mrgRDh6Uc9W0qe+4\n/P37xb99zjne02+6ScTc6biOHmX++GOpoDt0qO+fZjbCLVu2lM+yZTJ92zbZ9rBh8saWlCSvwZFg\n5EiJLKmrkzdCIuYnn4zMvv71Lzne1q0NX340cXLTffaZlOvBB6NSjEYj9O+9J0cU7lDosFFXJ37S\nc85x11nDiaIiOdCXX64/78YbRaRVw+q554p1auamm8SSy86WRi07H7ZdmON114lQmKMynPj2Wynj\n22/7X9YXM2bIdhYsMKbV1YlfefTo0LbtlqoqsbCvusoIU+3VyztyZvFimf7UU4bFYbU+rbz8six3\n5pkiVmVlcn5vvDG08tbVSShpaqpYm2Y++ED22aWLzA+kzSQQ/vpX2c/q1RIdFuqbnS9qa8W1CNQ/\n3mhhbXjfu1caqQsKImeMWGg0Qv/f/8oRBeOajQrKz2rnFw2ETz6Rbdh1tJg+3RDGqip5Vbda4V9/\nLcukpsqD6JavvpL17GLVrdxyi+y7vNz99u3Yv7++NbhsmZTjH/8IbdvBsG+fiKVdrPro0XLMPXuK\n8PijulraWvLy5HjS0tjL3xwKGzcalryZujqpsADvRtxwU1IibwyPPCJvOwUFkdsXs7ijPv44svvw\nhQqlffRR+X/dddJ2Y3XNRZBGI/QqXHzu3KA3ETmqq8VH2aOHxP42aeLdWBUIjzwiccR2vs3yctn2\nffdJKBogUTVm6urEt2z3RuCLujqJTR4xwphWWSk1q9lqKS8XwQtXPop+/bw74TzxhIiIckfFC4WF\nRnx3IBFKtbViiV59tfiyI93ItGePVP6BRtMEyllniVULiMWb6IwaJS7VqVONt7so0miEftUq9mp3\njAmqy7sV1Qg6fbo0ImRlidUXSOif4pxzfEfAnHeeRIG88ILs0ynOOxhUtM/06RLDnZkp/wcMMHxm\nb70l08LVAHX33dI+oCqT/v3FzxyPTJggbrFg+hwkGn/7m/EGu359rEsTedTbdJMmEkQQzLMdAo1G\n6LdskSOaPDnoTQROTY10vmnVyugd2LQp80svGY2uhw+LT3nIEGPaxx/LsoE2UNXVSecVX5EFKkKm\nZ0+JKQ4nRUViTQMivmPHSietjAxp+PvgAznO/Pzw9f5T5+qbbyQsL9Den9Gkujq8FWtDprRU3nD6\n9Il1SaJDZaUYcE2bxiSBoC+hTwl3NsxY0qaNfEc1VfGWLTKs1QUXACedBDRrBixfDtx3H7BwIfDO\nO8DrrwM7dwIffggQyXqXXQb83/8BTz8NnHACMHo00KSJ//1t2gQcOAAMHuy8zEUXARMmAIWFwO23\nh+c4FccdB7z7LlBZCVx1lXHSr7gCuPZa4Prr5f9LLxnHGiqnny7fCxYA7drJ70suCc+2w01KCtC+\nfaxLER9kZQGTJgE9e8a6JNGhSRN5Nmprgd69Y10ab5xqgFh9QrHoa2qCM5ID5ehRU7SfamA1uynq\n6pj/+EdpjOneXcK+Lrmk/ob27TNybGRkiCvku+98W8L//Ce76XJd26cfH0Br+w47kaK6WpJwnXRS\n+P3nJ50kvThHjZJzGoFcIRpNQwY+LPq4GGEqXCQnAy1bisEbKb74AsjNBW67zTPhp5/k+8QTjYWI\ngHvvFQv06FHg0CHguefqbyw9XQa9mDULOPdc4O9/B4YMAXr1Ap59Fti2rf46S5YAaWl+LYYPuj2O\nLvgFRwaPCOYwgyMlRcZzXLPGsLzDxYgRwLffAvPnAxdfHL63BY2mEZBQQg+IJyESrpuqKuCBB4BR\no4Ddu4F16zwz1q+XV/X09PorDRsmord8OZCfb7/hlBTZ6JQpQHEx8NZbsr1HHgHy8kTUDh40ll+6\nFBg4UNbzwaYTL0IZ2qKYOgZ1vHHH8OFARYW4jOLVbaPRxCkJJ/Rt29oL/a5dwQ8cXlQkbuJJk4Bf\n/QoYMwYoLfXM/OknscAd2MsZWHSkn7sdtWkDjBsH/O9/wObNwOOPyyvE5ZeLwFVXAytWACef7HdT\nZUdSAZjK2dA54wz5btMGOO202JZFo2lgJJzQO1n0zz8vRmFREKPWvvCCjN87fbq0q3bpIgLKdSwW\nvdltY+H114GRI4G6ugB32rUr8OST4s6ZNw+48UZ5Ozh61HdDrAd1DhJG6LOygKFDgauvBlJTY10a\njaZBkVBRN4AI/e7d9afv2CEG8auviugHwpo1QP/+EhgDiOZUVQEHt+xB6/37fVr0Bw6IMV5RIYOX\nB8wNN4haP/AAsGqVTHNj0XuE3u5cNFgWLACSEs420WgijqunhojOJ6JCItpERA/ZzO9CRPOIaA0R\nLSCiTqZ5LxDRj57PmHAW3g4ni764WL7/+ldvl7c/mIEffwQKCoxp2dnyXfrdZvnhw6I/ckS+Dx1y\nv8963H+/hGsWFsoo8d26+V0l4Sx6QCz55ORYl0KjaXD4FXoiSoYM/j0KQD6Aa4jI2rI4CcB7zNwH\nwEQAz3nWvRDAAAD9AJwC4H4iah2+4tfHSehLSiSct6xMvCFuKS0F9u71DnI5JvSrd8kPHxa9EvrD\nh93v05Y//EFi48eNcxVxkpBCr9FogsKNRT8YwCZm3szMVQA+BHCpZZl8APM9v78yzc8H8DUz1zDz\nYQBrAJwferGdadPGPryypESCW04/HXj5ZXHjuGHtWvm2tejX7xV/TE6O4/phE/qkJPE7vfCCq8W1\n0Gs0GoUboc8BsN30f4dnmpnVAK7w/L4cQCsiyvRMP5+ImhNROwBnAsgNrci+adNG/OdHjxrTDh8W\n10mHDuLq3rZNGlbd8OOP8l3w6zOkxxsMod+9+aC8JvjwG4dN6ANEVXZa6DUaTbhatu4HMJyIVgIY\nDqAIQC0zfwlgFoBFAKYAWAyg1royEY0nomVEtGx3iK2HdmkQSkrku3174MILRZsnTRL/uz/WrgUy\nUsrQfuM30lkJ0hgLAKVF1T7dNkBshJ45QRtjNRpNULgR+iJ4W+GdPNOOwcw7mfkKZu4P4BHPtAOe\n72eYuR8znwOAAGyw7oCZ32TmQcw8KEupaJC0bSvfTkKflCTtmitWSBCHP35cU4eC2jUgAPjsMwBA\n06ZA69aM0rImPhtigTA1xgZIRQVQUyO/tUWv0WjcCP1SAD2IqCsRNQEwFsAM8wJE1I6I1LYeBjDZ\nMz3Z48IBEfUB0AfAl+EqvB3+LHpAcollZ0sag5UrnbfFDKz9sQ69+QdJO+ARegDIblOJUmTHpUWv\njj09XSz6gGP4NRpNQuFX6Jm5BsAEALMBrAcwjZnXEtFEIlJ90UcAKCSiDQDaA3jGMz0VwDdEtA7A\nmwCu92wvYvgS+g4d5LtZM+Cjj8SPP2SItHHauXGKioCyQykowFrgrrskjt3T4yq72UERepcWfSyE\nvkcPsewjmftHo9HEP646TDHzLIiv3TztcdPv6QDqNW8y81FI5E3UsBN6FUNv9goNGya6ffPNouFz\n5wLvvWesDxgRN727VQDX3SERL59/Dowbhyzag83IAo4/3md5AhH6ujpgxgzvOP8uXYze/24xC/2S\nJWLVZ2QEtg1NeNi6Vb7z8mJZCk1jJyF7xgLeVmxJCZCZWb/nfLt2Iqx//rP47Z9/3jvJ5I+rawEk\no/fI9hJfmZsr7ptx45BdXYTvkvuKw94Hgfjoly6VtDZmkpNF+NPS/K+vMAs9IH76xpISPN644w4J\n1pozJ9Yl0TRmEq4/uZPrxmksCCLgnnuAc86RcUHMLpy1X+9FexSj3fmDZMELLhDTv7IS2Qd/xu7a\nDL/+70As+j175Pvjj2V8kaefFpHYt8//umZUJadeNnSDbOzYu1cS6mk0sSThhL5VK/l2K/SKMWPk\nNXvpUmPaj6trUIAfjRGOLrxQTPMFC5C9vxB1SPYpwtXVRvSLG6EvL5fvE08EuneXgaeAwIXezqLX\nxIaKCmD//liXQtPYSTihT04GWreu76NXDbHHKC83zG3IyH6pqcDUqfK/rg5YtysdvdN3GT2kRo4U\nV81f/oKsWjHTfMWpmzbvSuiVb761J0lEZqZ8793rf10z6tiVRa9j6WNHRUXgFbVGE24STuiB+vlu\n6ln0v/wiA4H07Al88w0ACUU87zxg2jQR+V821+JwbRoKTjLllWnRQkY6mjkT2RAz2Ze1bBZ6Nz56\nJfTqrUQ1oAZj0RNJn4KMDG3Rx5IjRyS6q6Ii1iXRNGYSXuiPHBGRPSb0e/aIoh8+LNb5iBHHnOFj\nxkg648WLgbUztwCANMSaufBCAAhY6N26boiMdMahCH2bNtI5LCtLC30sUQKv3TeaWJLwQu/VWerw\nYRHqX36RcJsVK4CxY4HHHgPOPReXDC5G06bivvlxrsRk9r7aMjarEnqVBiGMQn/woIx5q1LnhOK6\nUY3S2dla6GOJuge00GtiScIKvYo8UTH07TNrgCuvBJYtk/Ca008XZ/gHHwCTJwPffYfWp/XBBQOL\n8e9/A2tW1yE3ZSfa9DrOe+PdugH5+cjs2wlE7nz0RO4teuW2AYDmzYEmTYK36AEReu2jjw21tUaW\nVO2n18SShBV6q0Xf4Z8vyfirf/sbcKkpyzKR9Jpatgzo0AFjFt2N4mLg4x0no3d7B1N65kykTH7T\nr/9bCX27du599K1N2fqJxH0TTHiltuhjj9kvry16TSxpNELfftorwN13y8AddvTqBXz/PS4a1xHN\ncRhHYWmINdO1K5Cb61dEldBnZQVn0QPivgnVdbN3rxHmqYkeZtedFnpNLElIoW/bVsSOGSj5RRLT\nZ5+Q7t3t1Y60NLR460+4eKiY0L0v6OJz8XALvdWiB4Kz6M1Cn5Ul5yHQykITOmaLXrtuNLEkIYW+\nTRvxjR49CpR8/C0ysBep7092nUfgxkdzQQQMPquVz+X8+b+DEXqrRR+q0B8bDUu7b6KOtug18ULC\nCj0AlE2bjeKfDqBDuxpg8K1M4xUAACAASURBVGDX648aJY24+X7SsfkLXVQWXVaWVDq19YZc8SYc\nrhs16IhV6HWDbPTRFr0mXkhsob9vIkqad0P7gsAHM1EC6W+Zffucx581W/SAf6s+HK6bI0ekQlED\nsGiLPnZoi14TLyS00B/YW4OS9J5o3yEyh6lEVCUjsxKo0DtZ9IH0rFSN0Np1E3u0Ra+JFxJa6MvQ\nBiUHmvpNaBYs/kT0yBHJn6PK40voKyvlzcDOogfcu29U/wG1z/R0yf+jhT76KKFv105b9JrYktBC\nvwsdcfBwcsSF3sn/feSIdHpq2VL++xJ6a54bRaBpEKwWfVKSCI320Ucf9UaXk6OFXhNbElLolX96\nIyRPb73MlWEiy08aBCX0KneNr05TKkWxnesGCF7oAd1pKlYoi/6447TrRhNbElLolchtgCR0j6Xr\nxiz0biz6UF03WujjB6tFbzcusUYTDVwJPRGdT0SFRLSJiB6ymd+FiOYR0RoiWkBEnUzz/kBEa4lo\nPRG9QkQO3U3DR8uWABGjEDJ+XqSEvm1bICUlPELvZNGH6roBtNDHCmXR5+RIJJR5LGCNJpr4FXoi\nSgbwGoBRkIG+ryEia4T5JADvMXMfABMBPOdZdyiAYQD6ACgAcDKA4WErvQNJSUDrppXHXDeREnqV\nBjiSPvpgXTfKfQX4LqMmcphdN4D202tihxuLfjCATcy8mZmrAHwI4FLLMvkA5nt+f2WazwCaAWgC\noCmAVAAloRbaDW2aHkUFmgNwFxMfLL46TQXio3dy3aSlSdr8QFw3ycnGPgE5/rIyiezRRA8VdaXa\ncrTQa2KFG6HPAbDd9H+HZ5qZ1QCu8Py+HEArIspk5sUQ4d/l+cxm5vXWHRDReCJaRkTLdofJ9GzT\nRMypjAxJ9RspfLlFwuG6CTSD5YEDUlmYHWS6d2xsqKiQ6x/sADIaTbgIV2Ps/QCGE9FKiGumCEAt\nER0PoBeATpDKYSQRnW5dmZnfZOZBzDwoKyvwXqx2tEkVoY+U20YRLqF3sugBcd8E4rox++dVGQHt\np482R47IG1l6uvzXFr0mVqS4WKYIQK7pfyfPtGMw8054LHoiaglgNDMfIKLbAHzHzIc88z4HcCqA\nb8JQdp+0TRVVjYbQ+/PRJyeL+8WNRa/8+WYCsejthN5fGKgmMlRUeAu9tug1scKNRb8UQA8i6kpE\nTQCMBTDDvAARtSMita2HAUz2/N4GsfRTiCgVYu3Xc91EgjYp0RH6rCyxxu1SFCihB0TA/Vn0LVoY\nwwiaycgIzEfvZNFr1010UddfuW60Ra+JFX6FnplrAEwAMBsi0tOYeS0RTSSiSzyLjQBQSEQbALQH\n8Ixn+nQAPwP4AeLHX83Mn4b3EOxpkywtn9Gw6AF7ETULfYsW/htj7dw2gHbdNFSURd+8uTTKaote\nEyvcuG7AzLMAzLJMe9z0ezpE1K3r1QK4PcQyBoUS+kj1ilWYRbRzZ2M6c32h9+e6sTbEKkJ13bRq\nJa4jLfTRRTXGqgb1RLDoKyuB3/wGeOwxoIvvcXk0cURC9owFgDYkTu9YWfSVlSL2boXel0WfkSEZ\nLM1pb50oK/OOoQdEaHSnqeijGmMB8dMngtCvWwf8/e8y/LKm4aCFPkSc3CJKlN366H1Z9G47TVkH\nHTGjO01FH+W6AUToE8F1o+5zbTQ0LBJW6DNIzKeOHSO7HxXRUmLpBmYVejc+el+uG8C/UBw6BNTV\n2Qt9+/bAZ59JyoaUFPEZjx1rpDXWhB+z6y5RXDfKWNBGQ8PClY++IXJx6//h7Z7N0L//AxHdT8uW\n9g1tdkIfiusG8B95Y5fnRvHUU8CAAcb/ffuAt94Cvv8e+PBD4JRTfG9bEzhWi37t2tiWJxxoi75h\nkrBCn1Z7CLd2mQtQZIWeyN7/GqjQB+O6KSkRf3zTpvLfl9CffLJ8zNxwA3DNNcBppwHPPAM88IB3\nj9pgqKsDdu2SRF6NHdUYCySORa+FvmGSsK4bVFYaChhh7B7iQH30bix6s9DX1gIFBcD/+3/GNF9C\nb8eQIcDKlcCllwIPPhieBrb//Afo2hUoKvK/bKJjbYwtK/M/QHy8o4W+YZK4Ql9VFdkkNybsGtqU\n0KsH3ZePvqpK6iV/Pnqz66awUMaqnTfPmBao0APyRvC3v8nv9WHoyrZhgwyJuGRJ6NtqyNTVyTVV\nFb3qHdvQ20S0j75hkrhCH2cWfYsWIoDV1fXXd0pRrGjeHGjWzLsyWbFCvpcvl9BLIDihV+VPSwO2\nb/e/rD9Uo7QqX2NF9ZRWFX2i9I5VlvyePQ3/7aQxkbhCH2OLXj3oZqEH7N03Ks+Nk+sGqN9pSglp\ndbWIPWBYi9Y4en8QAbm5WujDiVXoEyXfjRL6urqGfyyNCS30YcBNY6yvwUf8WfSANMiaXTcrVwLd\nu8vvRYvkO1iLHgif0BcXG+VrzFivfyJZ9KqhXfvpGw6JK/RRdt1YG9rsXDeAvZ/ejdCbLfq6OrGY\nzz0X6NHDW+iTk419BkLnzuG16Hftko8vamuB++8Htm0Lfb/xRiJa9IcPy33du7f81376hkPiCn2U\nLXrAu6HNSejD4brZskXW6d8fGDpUhN7cKzaYEMncXLHGq6oCX9dMSQnQp4/89mfVb9kCvPQSMHNm\naPuMR6yuu0Sw6JWwFxTIt7boGw6JLfRRtOgB74fYLuoGCI/rRvm/BwwQoS8tBTZvdk5/4IbcXKks\ndu4Mbn1AXqIOHADOO8+7nE6oCi4RB822Xv9EGHxECbsW+oZHYgp9XR1QUxN1i978Wn7kiETKqPzy\nvnz0gVj0zCKgKSnywA0dKvMXLQpd6IHQ3DfKbdOjh3z8WfSqTUEdfyJhteibNJHfvlw3n38OjBwp\nt280WbAAGDTIfyWkhP3EE+WtUQt9aMyaFb3rnZhCr/wPURJ6J4ve7CsP1aLPyBCLuaJCBLSgQF5Y\n8vOlgognoW/fXt423Fr0iSj0Vose8N879uuvga++ktDFaPLttxK5pfpTOKFcNx06AO3aaR99qMyd\nK9fbVw6scJGYQl9ZKd9Rct3YvZY7Cb2vxli7YQQVKg3C3r0ioP37y/+kJODUU0XoDxwIPLRSEQmh\n37rVtwXbGCx6s9D7y2Cp7h8VuRQtlGX+yivGo+NruexsnfY6HKje41rogyXKFr2T68atRV9eLsum\n+Mg8pN4a1qwRS8qcoGzoUOCHH+TGCdaib9VK1g2X0KuKyJf7JpGF3toYD/i36NU8aybUSLN7t0Rr\n7doFTJnivFxpqTHYvRb60FFC7ys1SrjQQh8G3Fj0/uLofbltAEPo586Vb6vQM0tFE6zQA6HH0gcq\n9InsugnGolfzoi30paWS8K5PH2DSJLmXnJZT4y9kZWmhD5W4s+iJ6HwiKiSiTUT0kM38LkQ0j4jW\nENECIurkmX4mEa0yfY4S0WXhPoh6RNl107Rp/YY2q9CrB97JovfVEAsYrps5c6QhrG9fY97gwUaj\nbyyFvrhYjiMtTXy4nTv79tMnskVvbYwF/I8yFSuLvrRUKuf775dUyk7J7UpLjfEXtEUfGuYIt7iw\n6IkoGcBrAEYByAdwDRHlWxabBOA9Zu4DYCKA5wCAmb9i5n7M3A/ASABHAHwZxvLbE2WLHqj/Wm4V\n+qQk+e/ko3dr0a9dK1EPyhUEiLiedJL8jrVFbx7Ry1+DbCJb9ME0xipDIRY++qwsYMwY6fU6aZL9\ncrt3GxZ9dra0CYXa76Kxsnevce7ixaIfDGATM29m5ioAHwK41LJMPoD5nt9f2cwHgCsBfM7MLkY+\nDZEoW/RA/ddyq9ADzjnpAxF6wHCLmFFhlqEK/Z49hjUaKFah799fslk63ciJbtEnJ8ugNIr0dLkv\nnBo8Y2HR19XJNc/OFrvo7ruB+fPtK2iz60Z9RztCKFEwp/GOF6HPAWC283Z4pplZDeAKz+/LAbQi\nokzLMmMB2Db1ENF4IlpGRMt2hyNmKw4tesA5J70b101ammEdmv3zinAJPQDs2BHc+nYWPTOwerX9\n8olu0Vuvv6/esbW1Rs/qaAr9/v2ybyXc48eL0fHSS97LMdf30QPafRMsZqGPC9eNS+4HMJyIVgIY\nDqAIwLHML0TUEcBJAGbbrczMbzLzIGYelKXuoFCIgdBb/a/htugBQyjshP7884Gzz5bBRIIl1BDL\n4mKJsVaocjq5b5RFf+SI9G9LJMzDCCp85btR5wKIrtCbQyYBMRSuvBKYPdu7UbasTDKlWi16LfTB\nEY8WfRGAXNP/Tp5px2Dmncx8BTP3B/CIZ5p5iIWrAXzMzDbZ2CNAHLtu7C6qG4seMITeznXTrp00\n1Hbu7L7MVkIRepX+wGzRd+wo/52E3mzJR+NmjybmYQQVvtIgqGlpabEVegDo1098yGYRVy/a5sZY\n83RNYJhTjcSL0C8F0IOIuhJRE4gLZoZ5ASJqR0RqWw8DmGzZxjVwcNtEhDh13YRq0WdmyjB9wXaK\n8kenTvIdjNArUTALPZFUSr4sepWALdHcN+ZhBBW+XDfKSOjZU85ltAb1UNfN/CKtslP++GP95bRF\nHx6KiuScE8WJ64aZawBMgLhd1gOYxsxriWgiEV3iWWwEgEIi2gCgPYBn1PpElAd5I/hfWEvuixhZ\n9Kqhra5ORn1y46OvrpZl3Qj9o48Cf/5z+MpsRYVFBiP05hh6M127OidKKy83XD2JJvS+LHo7140S\n/xNPlPvHPPZAJFEWudmiV0nL1q41ptm5eFJTtdAHS1GRGFa+hhgNJz76Yhow8ywAsyzTHjf9ng5g\nusO6W1G/8TayxMiiB+SBVaLtxqJX6Q/cuG7OOiu0MrrBTYhlRYWc2uRkY5oSerOPHpC3kH37RLyS\nTGYFs4h7jx7SIzPRhD5Yi75XL/kuKfEW31CpqJAke9YU1kqo27UzpmVny3XzZdET6U5ToVBUJM/a\nzp1xYtE3SGLUGAvIQ2zX/R3wLfRuLPpo4E/oq6rE4nvkEe/pKvbbatFnZIjIW4X88GGZrtoFEk3o\n7Rpj1VgBdta62aIHwuunLykBunUDJk6sP6+0VETdnH6DSK6x2aJXlr+1QtA++uAoKpI+Cy1bxo+P\nvuERI9cNIJaZXWcZwP41zU2K4mjiT+inTJHc9wsWeE93ct0oK9bqrlBRJqpdINGE3q6NJjlZRNXO\nCrZa9OHqNMUM3HGHbM8uzNXc29VM795i0avIm9JSqajMj5TuHRsclZXS/yAnJ3qum8QU+hi7bvxZ\n9OawtXi06MvK7AcDYTZ6Ta5e7R0SWVIix2Ct3MxZN80oYW9MFj0gFaGdtb5/vyyvoqbCZdG//z7w\nySfittm6tf58c29XMwUFck1UGKA5hl6hXTfBoYbYPO4457414SaxhT7GFr1dY2xtrXe38XgUesDe\nqv/yS7Hyzj1XGpB/+smYZ+0spWisFr1dYyzgW+gzMuTNrmnT8Aj99u3AXXcBp50G3HijvdDbCThQ\nP/LGbjlt0QeHqjy16yZUlOsmDi16wLsGj0fXDWAv9JMmiRXywgvy3xw2ae0spXASenXcOTne/xMF\nu8ZYQM6RnYjv2yfGApFzZRAIzMCtt0pU17vvAt27y71pPc/+hF756e0s/+xsY8BwjXvMQu8Uch1u\nElPoY+C6UakH3Ai9uQZvKBb9qlWSIvnuuyWBWlqadwpiJ4veyXWjLPr0dLFq4lno//tf6YwWCL4s\nejv/u7LoAakMQvXRv/22lHnSJBH5Ll1k+i+/GMtUV0sFYyf0mZlSDrNFb/Xl23WaWrwY+PDD0Mqe\n6KhwY23Rh4qy6M0ZpSJMcrJ0ZNq3zz5FLeDboo8Xoc/JEavSKvSTJslNOX68HGu/ft4WvZPQO8WO\nq+Nu00beZuJV6KurgVtuAX7/e/frMPv20R85Uv/hVha9WiZUi37aNLHK77hD/uflybfZfaMSkjll\nHVGRN7W1RuIzM3b5bu66C7j33tDKnugUFUmbSXq6bowNjaoqseatQcMRRuW78eWjB7yFPt4s+tRU\nseTMQr99u1hpt91m9ModMEAs+ro6Od3799sLfUqKCLmTj7516/gW+rlzpezr1rkfxPnoUfl2Enqg\nvpDv3x9eoS8qkl626hFQQm+26O06S5np3VuEfs8eOXY71w1gCP3PPwPLlsnbm9PgJRq5NscdJ9dG\nN8aGghL6KKPy3QTqo2/WLKovH37p3NkQ+ooK4Le/ld93320s07+/VFI//2w86HY+ekDcAE5RN61a\nxbfQT50q30eO2Ddm2uH0RgcY58hO6JXrpn17EWG3FYsdKk5bkZUlFY/5GOzy3JgpKJDjXrrUfjmr\n0E+bJt/V1YmXuyicmK9Ny5Zyv0Q65UViCn1lZVQjbhQq302gPvp4aYhVqFj69euBU04Bpk8HnnrK\n8PMCRmbKlSudO0spMjLsLfpWraS3bLwKfWWlhCaq2HZzByJfOPWjAOwt+qoqqfzNFn1tbfBpEA4d\nkvNpFnoiuX6BCL1qkP3qK/n256NXlSKg89T7wiz0vsaSDieJKfQNyKJ3m9AsmuTmSqeogQNFxL/4\non5P2N695S1kxQrnzlIKO6EvLzcasH0JfSxdALNnS4X05JPy35wSwBe+LHp1jsyNrapXrLkx1rpM\nIJijOsx06eLturFLaGZGCf18z5BC1gqhRQupzEpLgcJC6VsxcqTMi1aunoaGGkLQbNEDWuiDIw4s\neqL6RbC7qOXl8Sf03brJ6/fQofLwnnde/WWaNJHoG7dCbxd1o95kWre276D19NNS2cSKqVPF7XT5\n5VL5hcOiV6JqtuhVJWi26K3LBIKK6jjuOO/peXneFv3u3dKwrvZrpXVrOW7Vo9bO8lex9FOnyj3/\nq1/JdC309hw4IIaAVegj7epKTKGPoUW/f78IefPm9duCnSz6eHPd3HILMHOmWLQdOzovp1IQ+3Pd\nqMRmZtxY9CtWiGso2BGvQqGiApgxA7jiCnlzUSkB3K4L2At9aqqcD7OIWy36UIXeyaLPyxOXirr/\nVMhkkg8VKCgQK5TICJU1o4T+ww+B0083xi7Wrht71LVRlbB23YRCDIW+ulosJbvXdqfG2Hiz6Js3\nBy680Ds7pR0DBojltmyZHIPdMQPGm465cdFq0ZeX13fTKKFbtCi44wiFWbPEyhozRv4XFEhPYDcj\nYTm57hTWTlPhtuh9uW4Aw33j1FnKjHLftGtnfz9kZwPffy/tOWPGGEnPtEVvj/XaaIs+FGLougHk\nYto95CpNbLw3xrpFNcjOnetszQNGBkvzcHllZd4WfV1d/R6WsRT6qVNFxIYPl/8FBXJb/fyz/3V9\nWfRA/fBJZdEroW/TRuyUUHz0rVsbIqKwxtK7EXqVm97Jj5+VJe6IpCRg9GgJv3XK0KmpL/R2ARqR\nIDGFPoYWPSCuBjuht4ubjcfGWLf06SMP+MGDvoVevfKb3Tfm4RPV8VvdN7ES+kOHxHV15ZVG+l5r\nSgBf+GqMBer3jrW6boicUyW4wRpaqbAK/e7dzgKuUMftVCGo6WeeKcelfP7adWOPtf1EN8aGQlVV\nXFr0gHdui6oqI8ywIdK8uZE/3Z9FD3gLvdWiB7yF/vBhEdzmzcVPH818KjNnilgrtw0gIZZE7vz0\nvhpjgfoWvTov5iEiQ+k0tXNn/YZYtc0mTQJz3ajj9if05nPVrp29Rc8MvPZa47b2i4rE8FHypF03\noVBZGVOLXjXG2qGE/uefgWHDpBfl4MHRK2O4Ue4bp85SgCH06gGvqRExNPvoAW+hVyI3apQsv2xZ\n+Mrsj4ULpUynnWZMa9FChkUMh0XfoYPcA6rC379fKj2zDzwUoXey6JOSjFj6igp5E/Mn9C1ayJuN\nCpu0MnSoNMqPHm1My8y0t+g3bQImTJA8PI0V67WJq8ZYIjqfiAqJaBMRPWQzvwsRzSOiNUS0gIg6\nmeZ1JqIviWg9Ea3zjCEbWWLkulGCBvgW+m+/lYfj55+Bjz4Crr46OuWLBEroA3HdmPPcAL6F/rLL\n5Dua7pvt20UQrdEoBQXhs+gB4xjNeW7MywQj9HV1ku/cTugBI8TSX/oDM9OmAbffbj/v1FMlOsp8\n79v1hAYMt4U5GV5jwyr0cWPRE1EygNcAjAKQD+AaIsq3LDYJwHvM3AfARADPmea9B+BFZu4FYDCA\nyGewjlFjrPlhdRL6li3lQevTRzJCXn55VIoWMdwIvdV1Y03N7Evo8/PFPRRtoVdZPM307g1s2OA9\nnoAdbhpjAeMYzXluzMuUlgaeBqG0VN6AnIRedZry11kqFJxcN2rAjWgL/eHDwNixEh0UaV55RT5O\nmDtLAcY9EnOhh4jzJmbezMxVAD4EcKllmXwAnv5z+ErN91QIKcw8BwCY+RAzR97bGiOLvmVL4/Xb\nSejvuQf4wx9kKD41mlBDZsgQeR2/8ELnZZSIqYdfRd/4sujNsflDh4rQR6uXrJPQFxSIiG7Y4Hv9\nigp5G3C6Ba29Y/ft87aIAXHvBJMGwZwC1468PKlgtm2T/+EcgFzh5LpRQr9hQ3RTXvzudxJFNXNm\nZPfDLGM1vPCC/b1aXS3n3nxtkpKik5PejdDnADAnrd3hmWZmNYArPL8vB9CKiDIBnADgABF9REQr\niehFzxuCF0Q0noiWEdGy3eEYbThGjbFExgPrJPRXXQU88ID3YMwNmaZNgVdfNUaKsiMlRUQ9GIs+\nO1uEfu9eYOPG8JbdjooKESknoQf8++nVoCNOyVPdWvTmZdxi7ZBjRUXeOCUqCweZmXIe1ZuNQgk9\nYD9+bSSYMwd4/XX5rSrBSLFtm+xj506jIjVTXCwVgPXaRCMnfbgaY+8HMJyIVgIYDqAIQC2AFACn\ne+afDKAbgJusKzPzm8w8iJkHZYXjXTJGjbGA8cA6CX1jxZzvxmrR24VXlpTIOqmpIvSAtG1EGpW1\n007oe/aUNzZ/fnqnQUcUSlzNQm+16EMVel+uGyCyQu/UaWrXLsMnbR7LIFKUlUkv7xNPFLebOjeR\nwuxetHM1KvG3Xpto5KR3I/RFAMy3fSfPtGMw805mvoKZ+wN4xDPtAMT6X+Vx+9QA+ATAgLCU3Bcx\nct0A/i36xoo5343Vom/aVD5WoVeRPD17SgUaDT+9L6Fv2hTo0cO9Re+EOQ0Cs3NjLBB4p6miInEH\nOLWZmC36Zs3qd6oKB6rx3eq+2bVLBLdDh+j46e+5R/b5j3/IKFvREPoWLeRjd6/+73/yPWiQ9/Ro\n5KR3I/RLAfQgoq5E1ATAWAAzzAsQUTsiUtt6GMBk07ptiUiZ6SMBrAu92H6IUWMsYDywvh70xog5\n343Vogfq57sxj1iVlCTRHbEWesBdzht/Fj1gdJo6ckR8t+G06Dt0cHYNduwoFU15uTTERmJsHqfh\nI3ftkv0PGBB5i37GDBkr9+GHJXw5Jyc6Qn/KKbI/u3v1yy9lZDZrJRwXrhuPJT4BwGwA6wFMY+a1\nRDSRiC7xLDYCQCERbQDQHsAznnVrIW6beUT0AwAC8FbYj8JKDC167bqxx+y6sRsQ3ZrBsrjY+4EY\nOlRGeVK9SCOFEnqnNoeCAgmLtfqfzfiz6AEjfNKa50bRtq3cwoEKvTWqw0pyslGJRcJtAzi7boqL\nDaFft873OQyVJ56QSvmxx+R/To7cO5Ha56FD0u4wdKiR9dUs3ocOififc079deOlMRbMPIuZT2Dm\n7sysRPxxZp7h+T2dmXt4lhnHzJWmdecwcx9mPomZb/JE7kSOujoJjdCum7jC7LopKxOL0yyGvix6\nwPDTf/ddZMu5fbtYus2a2c/v3VtusZ9+ct6G03ixZlSKA2ueGwVRcLH0apg6Xyj3TaSE3s51U1kp\nlVrHjtKHpLYW+OGHyOy/tlaSrI0aZciAqvwi1SC7dKnsd+hQ6QhZW2u0gwDitqmuBs49t/66cWHR\nNzhUkHOMXTda6L3JzDQyWKo8N2a3gVno1eDZ5t62J58s1miw7puFC91FejiFVircRN64dd2Yhd7q\nulHLOPnoa2uBt94yxqdVOPWKNRNpobf2hAaM41AWPRA5P/327VKxnHCCMU2dk2DcN//6l/cYynao\n+3LIEPmYpwHitmnWzLu3tSJeGmMbFkrotUUfV2RkSMNjWZl3nhuFWejtBjJp2VJE1mwlBcKvfgU8\n+KD/5fwJ/fHHy9vI+vXOy7h13Rw6ZOTatxv8o2NHZwt00SJg/Hjg/feNaRUVUnH4E3oVeROJzlKA\nPHqtW3sLvQqt7NhR9p+eHjk/fWGhfPfsaUxTbzmBCv2+fcB118m4BNXVzsstWiSd+9LT5ZOf7y30\nc+YAZ5xh/6YYL42xDQtt0ccl5t6x5syVCrPQOw1kctJJ7kd5slJc7D2MnhP+hD41VYTKV7pitxY9\nYFQYdhZ9Xp6U2a7zzZYt8j1njjHNX2ilebtA5Cx6oH6nKbPQExmD1kQCO6EP1qJX21q2DHj+eftl\n6uqAxYsN9yIgvxcvlnlq/GU7tw2gXTfBUelpHtAWfVxhjsQIxqIHxD++Y4d3Xns31NTIfrdv9927\ntrxcPr6EHpBQPV9C79aiBwxfv51F36WLlOfAgfrzVKrhuXPFjQM4DyFoJVpC72TRA+K+WbPGt5Uc\nLBs2yP1kPr42beSZDNRHr4R+2DBg4kT7yqmwUN6krEK/f7/MU5Wxk9C3aCHGgbqOkSDxhD7Grpth\nw4AbbojtWKfxSCAWvRJ6a0ZMtz1TrezdKwJ/+LC9aCr8hVYquneXwdOdcGPRq2Nbv17aHuxSVStB\ntnsTUUK/fz+wfLn8dmvRDxoE3HgjcPbZvpcLBWu+m127JExWie+AAfKo+nKBBUthoVjz5jYgouBC\nLDdsEFfdRx+Jq+uGGwxbUqFcNFahV/PmzJHrre5fK6ovQyRTcSee0KurECPXTUaGdNBoqKNGRQqz\n0DtZ9JWV8jGnPzATyOAfZkpNafR8Naq5Ffpu3eQ4nCoNN1E3yqLfuFGsebt4dutAIWZ++UU6bwGG\nxehW6Js3lxhzf8uFb3MkFAAAIABJREFUgp3rJjvbyAWlGmQj4b5RQm8lGKEvLJSKPTtb0iuvXSuh\nm2YWLZL729z4e8IJMm3hQrk+55zj3GchGqNMJZ7Qx9ii19hjdt04WfSAxNKb0x+Y6dJFHgq3g3Qr\nzOmTwiH03bvLt537htmd60ZVYtXV9m4bwGg0tRP6rVvlrXHAAInoAETEWrSIDyPD6ropLvZ+Q+vR\nQ8oabqE/ckSuo53QH3dccEKvtnXBBcBttwEvvgj85S+GG3DRIrHgrW8QQ4dKiue9e53dNkB0RplK\nXKGPkUWvsUeNnuTkozfnu7F2llIkJUk0QyQteiL/Pm5fQl9VJQLgz3WTmmq85dg1xAIili1a1Hfd\n1NZK3pS8PBGQRYukglShlZHo7Roo7drJtVQ+eNUrVpGUJL1Ewy30KvGd2bpW5OSIj95tFtTaWhks\nxVxp/PGPEp9/550SibNpk7SzmN02iqFDDXeMLzdZNHLSJ57Qx7gxVmOPymC5a5c8/E4WfXm5d54b\nK24H/zATiNCrFAG+6NZNvu2E3t+gI2ZUZeZk0RMZA4WY2bVLGpjz8sQlUFMjHXKchhCMBdY0CFah\nB+RtZNWqwHPu+8Iu4kaRkyMVsdvUz9u2iZyYt9WyJfDppyL4n30mlRXgLPSAjD3hawQ27boJBu26\niVsyM42wQDsfPWAIvVNSrt69ZX4gg0+XlopvuFMn/0Lvz20DyMPevr290PsbRtCMevidLHrAXujV\n/y5dpPE/LU3cN246S0ULcxqE2lq5ZnZCf/iwIc7hQI0VoNovzAQaYqnKZX07IALuvVfepDp0EKE+\n+eT66598stwHvsZqALTrJjhi3BircSYjwxB6fxa9k9AHE3lTWioRE507h0foAbHq7SJvwmnRA8aI\nUGaU0OflyW0+YgQwe7b/PDfRxGzR794tVrtV6FUP0sWLw7ffwkK5hnYVbbBCb/d2AEj00urV8oZp\nt7/mzSWEVOXbcUK7boJBW/RxS0aGIVpOFn1xsfibfVn0QGBCv3u3CH1urrPQMwcm9E6x9P6GETTj\nRujz8iSE0tx3QJ1DNULZOecYQxzGm9Dv2VM/hl6hIlPCmZXUKeIGCFzoN2yQtiVfPYhbtDCio+zo\n3t3/vRCNAcITV+i1RR93ZGYajXNOFv2mTfLt5NPMyZFKIhA/fWmpRLnk5kqHK7vGuH37RKQDEXqV\nU8VMIK4bJfT+XDeAt1W/dascj9qHOaIjXoTe7LpxEvpwp59m9i306p4KxKI/4YTIN25riz4YdGNs\n3GIWNCeLXkVNOFn0ROK+CdR1o4S+stI73FLhNrRS0b27CIvVfx6I60YJjz/XDVBf6M1WZH6+0Qgb\nj42xTkIPSIPl+vVGuuZQKC0V159dxA0gkpCd7b53rK9KI5zoxthg0K6buMUs9FaLvnlzsfD8CT1g\nDP7hNkzOLPSAvfsmGKEH6rtvImXRmyuUX34xKgBAKj+V5zxeLPq0NPmYXTd2b2nhTD/tz6cOuO80\ndfiwvP1FQ+jVvaJdN4GgXTdxi7LygPoWPZGIv3Ld+BL6ggKxAN3kaq+sNEZTCqfQO4VYBmLRDxkC\nXH650ShpR1aWbEsJfV2dCL3VL/zrXwPXXx8/Qg8YaRCKi+WtxS5zY6jpp82EU+iVwRENoU9Kinyq\n4sQTeu26iVt8WfRqmrKIfSXcUg2ybvz0yk3jxqJPSfFdwZhp314ezlAs+owMyaHi61iJvCNvSkrE\nlrEK/eDBkrJYpRiIB1Tv2F27nNtcWrSQWPRwCP2GDWLf+aqs3Qq9U2hlpIj0KFOJJ/TadRO3KKFP\nS7PvlKTEPyPD9+ULJMRSdZbKzhbruEkTZ6HPyXEvlET2IZaBRN24xRxLb46hj3dUvhu7zlJmhg0D\nvv9eOn6FQmGhxM/7uobHHSdlsjaiW9mwQa6xXTx+JIh0quLEE3odRx+3KNeNUy4WNd2fVZ2dLW4B\nNxa9WeiTkpw7TQUSWqmwC7EMxHXjFjuh9xXSFy8o140/oVepAtasCW1/bhpPlWtLtRv42lbnzuG9\njr6IC9cNEZ1PRIVEtImIHrKZ34WI5hHRGiJaQESdTPNqiWiV5zMjnIW3RVn0/vqxa6KOsuit/nmF\nW6EH3EfeKNeNioV2iqUPVug3b/buwh+I68YtXbqIYB46ZLhwEsmiN6f0DQTzQPHV1XIt/Lla3MbS\nq9DKaBHpUab8Cj0RJQN4DcAoAPkAriGifMtikwC8x8x9AEwE8JxpXgUz9/N8LglTuZ2pqpL383jI\n7KTxQgl9qBY9IH76tWv9R96YLXrAvndsXZ1EWAQj9EePeluH27eLjRHOF0pzLP3WrSKgKvY6nsnM\nlEbzykrfQp+bK29agQj9rFlyP911l1yDLVvE9ePWovcl9P7i8SNBPLhuBgPYxMybmbkKwIcALrUs\nkw9gvuf3Vzbzo0dlpfbPxykqXtyfRe8rAZSioECiadSYq06UloroquyYubnykJtH8yktFYswUKG3\nRt6UlUmD6FVXhdfOMIdYWmPo4xnVaQrwLfSAWPWBCP3HH0vj+auvSqerTz+V6eEQ+pIS6Z0dTaGP\nB9dNDgCzDbTDM83MagBXeH5fDqAVEalgumZEtIyIviOiy+x2QETjPcss223XmyUQlEWviTuSk6VL\nebgsesC/n17F0Cvhzc0VkVfj0gKBh1YqrLH0b70lAnHffYFtxx/mTlN2oZXxijmc1o3Q//KLu4gY\nZknidvHFwH//K1km779f5vlzt6SnS8Xvaz/RjrgB4sB145L7AQwnopUAhgMoAqBspi7MPAjAtQD+\nRETdrSsz85vMPIiZB2WFOjR9ZaVuiI1j+vQxRNpKIEKf73EeqjFXnVBCr7ALsVy5Ur6PP97/fs10\n6SKV188/i33xpz8BI0caoyeFi/bt5ZbeskUs+obgnwcCF3rAnVW/caOI+7nnApdcIonFRoyQweN9\ndT4DjCEFffWOdROPH24i7bpJcbFMEQCzrdPJM+0YzLwTHoueiFoCGM3MBzzzijzfm4loAYD+AHwM\nrRwi2qKPa/73P+d5gQh9RoY0ePrKRgkYCc0UZqFXHZWmThWRz7e2PPkhNVV8/ps3yzaKisSqDzdJ\nSSLuS5eKP7qhWPSBuG769ZMIl0WLxPXlCzWilsrx06kT8NVX7ntK+4ul37BByhLoG14oxEMc/VIA\nPYioKxE1ATAWgFf0DBG1IyK1rYcBTPZMTyeipmoZAMMArAtX4W2pqtIWfQMlEB89ke9slAp/Fn1J\nCbBgATBmTHB+9e7dpTfvpEnSbnD++YFvww1duhhpAhqK0CuLvnlz+8HPzaSmSi/Zb7/1v90vv5T2\nEdVGonB7/fwJvYrHT4pi8HnLlhJiam47Cid+D4WZawBMADAbwHoA05h5LRFNJCIVRTMCQCERbQDQ\nHsAznum9ACwjotWQRtrnmTmyQq8bYxssp50m43L26uVueX9Cz1xf6Nu2FetJrTd9ukTdjBkTXJm7\ndQOWLZMY8Pvui1ywV16e0UWkobluOnRwd17OPBNYvty7/cRKdbVY777GYPWHEnq7N4A9e4B586SB\nN5qoxGaqH0a4cVVnMfMsZj6Bmbsz8zOeaY8z8wzP7+nM3MOzzDhmrvRMX8TMJzFzX8/33yNzGCa0\n66bB0rOnDM/mNgbdn9AfPixx7Waht74JTJ0qLhvV2zZQVBbLjh2Ba64JbhtuMFvxDUXoW7USS92f\n20Zx1VVS6U6f7rzMd9+JLztUoT961DsOX/HGG3LP3HVX8NsPhkiPMpWYPWO166ZRkJtrjEFrh7Wz\nlHm97dvFqlu4MHi3DWBE3tx1V2RvOyXu6enO4anxBpH46d0Kfe/e8pk61XmZL78Ul8qZZwZfLpXK\n2TqEYUWFhGteeGHg7TWhEumc9Ikn9NqibzTk5oo17RRBYe0sZV5v+3bg3/+W9YN12wDik3/iCWDC\nhOC34QZl0TcUa17x8stG6KMbxoyRytepf8SXXwKnnCIuuGAZOVIa8++5xzu/zvvvi3EQSHnDRaRH\nmUpModcWfaPAVzZKwLfQFxcDH3wA9O0bWhhdixbAk09GvqeqEvqG0hCrGDNGhDmQ5QGphK3s2yft\nIaG4bQB5w3vjDWDJEuAPf5BpdXXASy8BAwcCw4eHtv1g0BZ9oOjG2EZDKELPLA1/oVjz0aRjR6lU\nopVNMVaccIKEWtq5b+bPF0EOVegB4Oqr5do/+aTE4c+cKWGV998fm+wpkR5lyk0cfcNCu24aDf6E\n3pePXtFQhD4pCfjmm4bnugmGMWOAhx+WDmJduxrTv/xSQnAHDw7Pfl57TUJrb7hBLOrOnYErrwzP\ntgNFN8YGinbdNBpatZKGSV8WfcuW9VPNKqEfNKh+LHY807+//56fiYCqfKdNM6YxA3PmiH89JUzm\naWamdHBbs0Y6at17b/i2HSjadRMo2nXTqPAVYmmNoVd06SIVxK23RrZsmuDo2lWsduW+2bsXuPRS\nSf9wSZjz3158MXDHHRKJE8v7IdKum8QTeu26aVQEI/TNm0ukzu23R7ZsmuAZM0ZyEL3zjvjsv/hC\ncgnddFP49/XGG5KvyF/v3UiiXTeBouPoGxXBCD0gYq+HLIhfVL6bW26Rx3nxYuDuuyN3zewGLo8m\nqpOgbox1i7boGxW5udLoevRo/Yd1927xw2saHrm58sZVUwP88Y/Oqa0ThaQkEftIWfSJKfTaom80\nqIbVHTu80wzb5bnRNCz++tdYlyC6RDJVcWK5burqpD+8tugbDU4hlgcOiDWohV7TUIjkKFOJJfQq\n6YkW+kaDk9A7dZbSaOKVSI4ylVhCr/K4atdNo6FTJ/m2Cr1TZymNJl7Rrhu3VFXJt7boGw1paZIh\nUVv0moZOJEeZSqzGWCX02qJvVNiFWGqh1zQ07rzTOeV2qCSW0CvXjbboGxW5uZIXxYwSevO4pRpN\nPBPuXr9mtOtG0+Cxs+g3bJBBxlNTY1MmjSaecCX0RHQ+ERUS0SYieshmfhcimkdEa4hoARF1ssxv\nTUQ7iOgv4Sq4Ldp10yjJzZVwStWQdfQoMGOGjBSk0WhcCD0RJQN4DcAoAPkAriEi60BbkwC8x8x9\nAEwE8Jxl/v8D8HXoxfWDdt00Sqwhlp9/Dhw82HBSEGs0kcaNRT8YwCZm3szMVQA+BHCpZZl8APM9\nv78yzyeigQDaA/gy9OL6QVv0jRKr0E+dKr75kSNjVyaNJp5wI/Q5AMwe0B2eaWZWA7jC8/tyAK2I\nKJOIkgC8BMDnKIxENJ6IlhHRst0qADoYtEXfKDEL/eHDwKefAqNHxy63uEYTb4SrMfZ+AMOJaCWA\n4QCKANQC+DWAWczsMNSvwMxvMvMgZh6UFUoPF90Y2yjJyZGshtu3A599Bhw5ot02Go0ZNzZPEQDT\n4Gvo5Jl2DGbeCY9FT0QtAYxm5gNEdCqA04no1wBaAmhCRIeYuV6DbljQrptGSWoq0KEDsG0b8MMP\n8vuMM2JdKo0mfnAj9EsB9CCirhCBHwvgWvMCRNQOwD5mrgPwMIDJAMDM15mWuQnAoIiJPKBdN42Y\n3Fxg3Tpg1Spg/HggOTnWJdJo4ge/rhtmrgEwAcBsAOsBTGPmtUQ0kYhUiP8IAIVEtAHS8PpMhMrr\nG+26abTk5gLffy91vXbbaDTeuGquYuZZAGZZpj1u+j0dwHQ/23gXwLsBlzAQdFKzRotqkO3UCTj1\n1NiWRaOJNxIrLkFb9I0WJfRXXy2j9SQK1dXV2LFjB44ePRrromjihGbNmqFTp05IDaDbd2IKvbbo\nGx35+RJ5c911/pdtSOzYsQOtWrVCXl4eSA9y2+hhZuzduxc7duxA165dXa+XQLYPdGNsI+a884Ct\nW4EBA2JdkvBy9OhRZGZmapHXAACICJmZmQG/4SWW0GvXTaOFCOjcOdaliAxa5DVmgrkftNBrNBpN\ngpNYQl9ZKb1ntAWk0YSFvXv3ol+/fujXrx86dOiAnJycY/+rlGHlh5tvvhmFhYU+l3nttdfwz3/+\nMxxF1tiQeI2xuiFWowkbmZmZWLVqFQDgySefRMuWLXH//d6pq5gZzIwkh3Cnd955x+9+fvOb34Re\n2ChTU1ODlAaSUCnxLHrtttEkKvfcA4wYEd7PPfcEVZRNmzYhPz8f1113HXr37o1du3Zh/PjxGDRo\nEHr37o2JEyceW/a0007DqlWrUFNTg7Zt2+Khhx5C3759ceqpp6LUMxTYo48+ij/96U/Hln/ooYcw\nePBg9OzZE4sWLQIAHD58GKNHj0Z+fj6uvPJKDBo06FglZOaJJ57AySefjIKCAtxxxx1gZgDAhg0b\nMHLkSPTt2xcDBgzA1q1bAQDPPvssTjrpJPTt2xePPPKIV5kBoLi4GMcffzwA4O2338Zll12GM888\nE+eddx7Ky8sxcuRIDBgwAH369MHMmTOPleOdd95Bnz590LdvX9x8880oKytDt27dUFNTAwDYv3+/\n1/9IklhCX1WlhV6jiRI//fQT7r33Xqxbtw45OTl4/vnnsWzZMqxevRpz5szBunXr6q1TVlaG4cOH\nY/Xq1Tj11FMxefJk220zM5YsWYIXX3zxWKXx6quvokOHDli3bh0ee+wxrFy50nbdu+++G0uXLsUP\nP/yAsrIyfPHFFwCAa665Bvfeey9Wr16NRYsWITs7G59++ik+//xzLFmyBKtXr8Z9993n97hXrlyJ\njz76CPPmzUNaWho++eQTrFixAnPnzsW9994LAFi9ejVeeOEFLFiwAKtXr8ZLL72ENm3aYNiwYcfK\nM2XKFFx11VVReStoGO8dbtGuG00i47F444Xu3btj0KBBx/5PmTIFf//731FTU4OdO3di3bp1yM/3\nHqMoLS0No0aNAgAMHDgQ33zzje22r7jiimPLKMt74cKFePDBBwEAffv2Re/evW3XnTdvHl588UUc\nPXoUe/bswcCBAzFkyBDs2bMHF198MQDpdAQAc+fOxS233IK0tDQAQEZGht/jPvfcc5Geng5AKqSH\nHnoICxcuRFJSErZv3449e/Zg/vz5GDNmzLHtqe9x48bhlVdewUUXXYR33nkH77//vt/9hYPEEnrt\nutFookaLFi2O/d64cSP+/Oc/Y8mSJWjbti2uv/5621jvJqbnMzk52dFt0dRjsPlaxo4jR45gwoQJ\nWLFiBXJycvDoo48G1as4JSUFdXV1AFBvffNxv/feeygrK8OKFSuQkpKCTp06+dzf8OHDMWHCBHz1\n1VdITU3FiSeeGHDZgiHxXDfaotdook55eTlatWqF1q1bY9euXZg9e3bY9zFs2DBMmzYNAPDDDz/Y\nuoYqKiqQlJSEdu3a4eDBg/jPf/4DAEhPT0dWVhY+/fRTACLeR44cwTnnnIPJkyejoqICALBv3z4A\nQF5eHpYvXw4AmD7dOY1XWVkZsrOzkZKSgjlz5qCoSDK4jxw5ElOnTj22PfUNANdffz2uu+463Hzz\nzSGdj0BILKHXFr1GExMGDBiA/Px8nHjiibjhhhswbNiwsO/jzjvvRFFREfLz8/HUU08hPz8f/7+9\n8w+uosry+OfgoJFfCb8KgViY3UEIJHlJgCS6IZCJIKAFBfIrooD8mqVGMrO1i6Wuhc5Q1NYoPy0p\nClQUtpTA6CCiIqOZ7EbXkSFECEiAuEscIJkQkJ+yimHO/tGd50sgkISQbt6eT9Wr1/f27e5v973v\nvNunb58bGRlZq0znzp2ZNm0a/fr1Y+TIkaSmpgbXvfHGGyxZsoSEhATS09OpqqriwQcfZMSIEQwc\nOJDExESWLVsGwPz581mxYgXJycmcOnWqXk2PPvoon332GfHx8eTm5tK7d2/AcS098cQTZGRkkJiY\nyPz584PbTJkyhTNnzjCpBcOsSs0Tab8wcOBALSwsbNrGw4c7s0L/6U/NK8owPKKkpITY2FivZfiC\n6upqqquriYiIoLS0lOHDh1NaWnrTDHGsITc3l+3btzdo2Gl9XKldiMguVR14pfI31xW6Fua6MYyw\n5fz582RlZVFdXY2qsnr16pvOyM+dO5ePP/44OPKmpbi5rtK1+P57aN/eaxWGYdwAoqKign7zm5VV\nq1Z5ctzw8tHbOHrDMIzLCD9Db64bwzCMWjTI0IvICBE5KCJfichlk3uLSC8RyRORYhH5DxGJDskv\nEpHdIvKliPxjc59ALWzUjWEYxmVc09CLyC3ASmAk0A/IFpF+dYotBtaragLwG+Df3PwK4B5VTQRS\ngSdFpEdzib8M69EbhmFcRkN69CnAV6r6P6p6EcgFxtQp0w/4o7ucX7NeVS+qqjvtE7c18HhNx3r0\nhtGsZGZmXvby0/Lly5k7d+5Vt2vXrh0A5eXljB8//oplhg4dyrWGUi9fvpwLFy4E06NGjeL06dMN\nkW6E0BDD2xM4EpI+6uaFsgcY5y6PBdqLSGcAEblTRIrdffxWVcvrHkBE5ohIoYgUVlVVNfYcfsQe\nxhpGs5KdnU1ubm6tvNzcXLKzsxu0fY8ePa76Zum1qGvoP/jgA6Kiopq8v5ZGVYOhFLykuXrY/wIM\nEZEvgCHAMeASgKoecV06PwWmiUi3uhur6hpVHaiqA7t27dp0Fea6McIYL6IUjx8/nvfffz84yUhZ\nWRnl5eUMHjw4OK49OTmZ+Ph4tmzZctn2ZWVlxMXFAU54gsmTJxMbG8vYsWODYQfAGV9eE+L42Wef\nBeDFF1+kvLyczMxMMjMzASc0wYkTJwBYunQpcXFxxMXFBUMcl5WVERsby+zZs+nfvz/Dhw+vdZwa\ntm7dSmpqKklJSdx3331UVlYCzlj9xx57jPj4eBISEoIhFD788EOSk5MJBAJkZWUBTnz+xYsXB/cZ\nFxdHWVkZZWVl9OnTh6lTpxIXF8eRI0eueH4AO3fu5N577yUQCJCSksK5c+fIyMioFX45PT2dPXv2\nXL2irkFDxtEfA+4MSUe7eUHcXvo4ABFpBzykqqfrlhGRfcBgoOl/8VfDXDeG0ax06tSJlJQUtm3b\nxpgxY8jNzWXixImICBEREWzevJkOHTpw4sQJ0tLSGD16dL1zmq5atYo2bdpQUlJCcXExySEzuS9a\ntIhOnTpx6dIlsrKyKC4uJicnh6VLl5Kfn0+XLl1q7WvXrl289tpr7NixA1UlNTWVIUOG0LFjR0pL\nS9mwYQMvv/wyEydO5O233+aRRx6ptX16ejqff/45IsIrr7zC888/z5IlS1i4cCGRkZHs3bsXcGLG\nV1VVMXv2bAoKCoiJiakVt6Y+SktLWbduHWlpafWeX9++fZk0aRIbN25k0KBBnD17lttvv52ZM2fy\n+uuvs3z5cg4dOsR3331HIBBoVL3VpSGGfifQW0RicAz8ZODh0AIi0gX4RlX/BjwFrHXzo4GTqvq/\nItIRSAeWXZfi+lCFH36wHr0RtngVpbjGfVNj6F999VXAcUs8/fTTFBQU0KpVK44dO0ZlZSV33HHH\nFfdTUFBATk4OAAkJCSQkJATXbdq0iTVr1lBdXU1FRQX79++vtb4un376KWPHjg1Gkhw3bhyffPIJ\no0ePJiYmhsTERKB2mONQjh49yqRJk6ioqODixYvExMQATtjiUFdVx44d2bp1KxkZGcEyDQll3KtX\nr6CRr+/8RITu3bszaNAgADp06ADAhAkTWLhwIS+88AJr165l+vTp1zzetbim60ZVq4HHge1ACbBJ\nVb8Ukd+IyGi32FDgoIgcAroBi9z8WGCHiOwB/hNYrKp7r1v1lbCJwQ3jhjBmzBjy8vIoKiriwoUL\nDBgwAHCChFVVVbFr1y52795Nt27dmhQS+PDhwyxevJi8vDyKi4t54IEHmrSfGm4L6ezVF+Z43rx5\nPP744+zdu5fVq1dfdyhjqB3OODSUcWPPr02bNgwbNowtW7awadMmpkyZ0mhtdWmQj15VP1DVu1X1\n71V1kZu3QFXfdZffUtXebplZNSNtVPUjVU1Q1YD7vea6FdeHGXrDuCG0a9eOzMxMZsyYUeshbE2I\n3tatW5Ofn8/XX3991f1kZGTw5ptvArBv3z6Ki4sBJ8Rx27ZtiYyMpLKykm3btgW3ad++PefOnbts\nX4MHD+add97hwoULfPvtt2zevJnBgwc3+JzOnDlDz57OmJJ169YF84cNG8bKlSuD6VOnTpGWlkZB\nQQGHDx8GaocyLioqAqCoqCi4vi71nV+fPn2oqKhg586dAJw7dy74pzRr1ixycnIYNGhQcJKT6yF8\n3oytMfTmujGMZic7O5s9e/bUMvRTpkyhsLCQ+Ph41q9ff81JNObOncv58+eJjY1lwYIFwTuDQCBA\nUlISffv25eGHH64V4njOnDmMGDEi+DC2huTkZKZPn05KSgqpqanMmjWLpKSkBp/Pc889x4QJExgw\nYEAt//8zzzzDqVOniIuLIxAIkJ+fT9euXVmzZg3jxo0jEAgEwws/9NBDfPPNN/Tv35+XXnqJu+++\n+4rHqu/8br31VjZu3Mi8efMIBAIMGzYs2NMfMGAAHTp0aLaY9eETpvj0afj5z2HGDLj//uYXZhge\nYGGK/39SXl7O0KFDOXDgAK1aXd4fb2yY4vDp0UdFwcaNZuQNw7ipWb9+PampqSxatOiKRr4phFeY\nYsMwjJucqVOnMnXq1GbdZ/j06A0jTPGbe9Xwlqa0BzP0huFjIiIiOHnypBl7A3CM/MmTJ4mIiGjU\ndua6MQwfEx0dzdGjR7muGFBGWBEREUF0dHSjtjFDbxg+pnXr1sE3Mg2jqZjrxjAMI8wxQ28YhhHm\nmKE3DMMIc3z3ZqyIVAFXD5pxdboAJ5pJTnPhR03gT11+1ASmqzH4URP4U1dzauqlqlec0MN3hv56\nEZHC+l4D9go/agJ/6vKjJjBdjcGPmsCfulpKk7luDMMwwhwz9IZhGGFOOBr6Gxfzvun4URP4U5cf\nNYHpagx+1AT+1NUimsLOR28YhmHUJhx79IZhGEYIZugNwzDCnLAx9CIyQkQOishXIvKkhzrWishx\nEdkXktdJRD6Z5SBFAAAD80lEQVQSkVL3+/ongWycpjtFJF9E9ovIlyLyS5/oihCRP4vIHlfXr938\nGBHZ4dblRhFp8YmAReQWEflCRN7zkaYyEdkrIrtFpNDN87QOXQ1RIvKWiBwQkRIRucdLXSLSx71G\nNZ+zIvIrn1yrf3Lb+j4R2eD+Bm542woLQy8itwArgZFAPyBbRPp5JOd1YESdvCeBPFXtDeS56Zak\nGvhnVe0HpAG/cK+P17q+B36mqgEgERghImnAb4FlqvpT4BQws4V1AfwSKAlJ+0ETQKaqJoaMvfa6\nDgFWAB+qal8ggHPdPNOlqgfda5QIDAAuAJu91AQgIj2BHGCgqsYBtwCTaYm2pao3/Qe4B9gekn4K\neMpDPXcB+0LSB4Hu7nJ34KDH12sLMMxPuoA2QBGQivOm4E+uVLctpCUaxxD8DHgPEK81ucctA7rU\nyfO0DoFI4DDuwA6/6ArRMRz4Lz9oAnoCR4BOOJGD3wPub4m2FRY9en68gDUcdfP8QjdVrXCX/wp0\n80qIiNwFJAE78IEu10WyGzgOfAT8N3BaVavdIl7U5XLgCeBvbrqzDzQBKPAHEdklInPcPK/rMAao\nAl5zXV2viEhbH+iqYTKwwV32VJOqHgMWA38BKoAzwC5aoG2Fi6G/aVDnb9uTMa0i0g54G/iVqp71\ngy5VvaTOLXY0kAL0bWkNoYjIg8BxVd3lpY56SFfVZBwX5S9EJCN0pUd1+BMgGVilqknAt9RxiXjV\ntlxf92jgd3XXeaHJfSYwBufPsQfQlsvdvDeEcDH0x4A7Q9LRbp5fqBSR7gDu9/GWFiAirXGM/Buq\n+nu/6KpBVU8D+Ti3rlEiUjMpTkvX5T8Ao0WkDMjFcd+s8FgTEOwRoqrHcXzOKXhfh0eBo6q6w02/\nhWP4vdYFzh9ikapWummvNd0HHFbVKlX9Afg9Tnu74W0rXAz9TqC3+/T6VpzbtXc91hTKu8A0d3ka\njo+8xRARAV4FSlR1qY90dRWRKHf5dpznBiU4Bn+8F7pU9SlVjVbVu3Da0R9VdYqXmgBEpK2ItK9Z\nxvE978PjOlTVvwJHRKSPm5UF7Pdal0s2P7ptwHtNfwHSRKSN+5usuVY3vm158YDkBj3oGAUcwvHx\n/quHOjbg+N9+wOntzMTx8eYBpcDHQKcW1pSOc5taDOx2P6N8oCsB+MLVtQ9Y4Ob/HfBn4Cuc2+7b\nPKrLocB7ftDkHn+P+/mypo17XYeuhkSg0K3Hd4COXuvCcYucBCJD8vxwrX4NHHDb+78Dt7VE27IQ\nCIZhGGFOuLhuDMMwjHowQ28YhhHmmKE3DMMIc8zQG4ZhhDlm6A3DMMIcM/SGYRhhjhl6wzCMMOf/\nAK9Vyqd+KloaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}